{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist =input_data.read_data_sets('MNIST_data/',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28#输入一行，每行28个数据\n",
    "max_time = 28#28个序列\n",
    "lstm_size = 100#隐藏单元,相当100个基础单元\n",
    "n_classes = 10#10个分类\n",
    "batch_size = 50#每批次50个样本\n",
    "n_batch = mnist.train.num_examples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.truncated_normal([lstm_size,n_classes],stddev=0.1))\n",
    "biases = tf.Variable(tf.constant(0.1,shape=[n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(X,weights,biases):\n",
    "    inputs = tf.reshape(X,[-1,max_time,n_inputs])\n",
    "    #定义最基本的单元\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(lstm_size)#传入100个block\n",
    "    #final_state[0]是cell state\n",
    "    #final_state[1]是hidden state\n",
    "    outputs,final_state = tf.nn.dynamic_rnn(lstm_cell,inputs,dtype=tf.float32)\n",
    "    results = tf.nn.softmax(tf.matmul(final_state[1],weights)+biases)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = RNN(x,weights,biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-f9788b2ad305>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 交叉熵代价函数\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "## 使用 AdamOptimizer进行优化\n",
    "#####不同的optimizer造成的结果一般千差万别\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "## 结果存放在一个布尔列表中\n",
    "correct_prediction = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1)) ## argmax返回一维张量中最大的值所在的位置\n",
    "## 求准确率\n",
    "accuracy= tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter0 ,Testing Accuracy0.6737training acc=0.6698909\n",
      "Iter1 ,Testing Accuracy0.7856training acc=0.77894545\n",
      "Iter2 ,Testing Accuracy0.8541training acc=0.8546364\n",
      "Iter3 ,Testing Accuracy0.8933training acc=0.89385456\n",
      "Iter4 ,Testing Accuracy0.9133training acc=0.91172725\n",
      "Iter5 ,Testing Accuracy0.9208training acc=0.92265457\n",
      "Iter6 ,Testing Accuracy0.9283training acc=0.9312\n",
      "Iter7 ,Testing Accuracy0.9279training acc=0.9261636\n",
      "Iter8 ,Testing Accuracy0.933training acc=0.93634546\n",
      "Iter9 ,Testing Accuracy0.9396training acc=0.9421818\n",
      "Iter10 ,Testing Accuracy0.9469training acc=0.9500727\n",
      "Iter11 ,Testing Accuracy0.9451training acc=0.9476909\n",
      "Iter12 ,Testing Accuracy0.9484training acc=0.9526727\n",
      "Iter13 ,Testing Accuracy0.952training acc=0.95574546\n",
      "Iter14 ,Testing Accuracy0.9451training acc=0.9509636\n",
      "Iter15 ,Testing Accuracy0.9561training acc=0.9594182\n",
      "Iter16 ,Testing Accuracy0.9549training acc=0.9619273\n",
      "Iter17 ,Testing Accuracy0.9549training acc=0.9592\n",
      "Iter18 ,Testing Accuracy0.9597training acc=0.9636545\n",
      "Iter19 ,Testing Accuracy0.9588training acc=0.9648727\n",
      "Iter20 ,Testing Accuracy0.9585training acc=0.96314543\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys =mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        \n",
    "       \n",
    "        train_acc = sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels})\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print (\"Iter\" + str(epoch)+\" ,Testing Accuracy\" +str(acc)+'training acc='+str(train_acc))\n",
    "    saver.save(sess,'net/my_net.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
