{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from keras.utils import np_utils#one hot\n",
    "import os\n",
    "from skimage import data\n",
    "from skimage import transform\n",
    "import skimage\n",
    "import numpy as np\n",
    "\n",
    "# Download the dataset\n",
    "\n",
    "\n",
    "def load_data(data_directory):\n",
    "    directories = [d for d in os.listdir(data_directory) \n",
    "                  if os.path.isdir(os.path.join(data_directory,d))]\n",
    "    labels=[]\n",
    "    images=[]\n",
    "    for d in directories:\n",
    "        label_directory = os.path.join(data_directory,d)\n",
    "        file_names = [os.path.join(label_directory,f)\n",
    "                     for f in os.listdir(label_directory)\n",
    "                     if f.endswith('.jpg')]\n",
    "        for f in file_names:\n",
    "            images.append(skimage.data.imread(f))\n",
    "            labels.append(str(d))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/home/tang/targa/BigSize1/'\n",
    "train_data_directory = os.path.join(ROOT_PATH, \"train\")\n",
    "validation_data_directory = os.path.join(ROOT_PATH, \"val\")\n",
    "test_data_directory = os.path.join(ROOT_PATH, \"test\")\n",
    "train_images,train_labels = load_data(train_data_directory)\n",
    "test_images,test_labels = load_data(test_data_directory)\n",
    "validation_images,validation_labels = load_data(validation_data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding trY teY\n",
    "from numpy import array\n",
    "#from numpy import argmax\n",
    "#from keras.utils import to_categorical\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# define example\n",
    "\n",
    "#train_labels = np_utils.to_categorical(train_labels,num_classes = None)\n",
    "#test_labels = np_utils.to_categorical(test_labels,num_classes = None)\n",
    "trL,teL,valL=array(train_labels),array(test_labels),array(validation_labels)\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_encoded_trL = label_encoder.fit_transform(trL)\n",
    "integer_encoded_teL = label_encoder.fit_transform(teL)\n",
    "integer_encoded_valL = label_encoder.fit_transform(valL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = np_utils.to_categorical(integer_encoded_trL,num_classes = 32)\n",
    "testLabels = np_utils.to_categorical(integer_encoded_teL,num_classes = 32)\n",
    "validationLabels = np_utils.to_categorical(integer_encoded_valL,num_classes = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "18\n",
      "J\n",
      "--------------------\n",
      "1\n",
      "18\n",
      "J\n",
      "--------------------\n",
      "2\n",
      "14\n",
      "E\n",
      "--------------------\n",
      "3\n",
      "7\n",
      "7\n",
      "--------------------\n",
      "4\n",
      "10\n",
      "A\n",
      "--------------------\n",
      "5\n",
      "25\n",
      "S\n",
      "--------------------\n",
      "6\n",
      "11\n",
      "B\n",
      "--------------------\n",
      "7\n",
      "20\n",
      "L\n",
      "--------------------\n",
      "8\n",
      "26\n",
      "T\n",
      "--------------------\n",
      "9\n",
      "31\n",
      "Z\n",
      "--------------------\n",
      "10\n",
      "23\n",
      "P\n",
      "--------------------\n",
      "11\n",
      "19\n",
      "K\n",
      "--------------------\n",
      "12\n",
      "12\n",
      "C\n",
      "--------------------\n",
      "13\n",
      "15\n",
      "F\n",
      "--------------------\n",
      "14\n",
      "22\n",
      "N\n",
      "--------------------\n",
      "15\n",
      "28\n",
      "W\n",
      "--------------------\n",
      "16\n",
      "9\n",
      "9\n",
      "--------------------\n",
      "17\n",
      "30\n",
      "Y\n",
      "--------------------\n",
      "18\n",
      "1\n",
      "1\n",
      "--------------------\n",
      "19\n",
      "3\n",
      "3\n",
      "--------------------\n",
      "20\n",
      "4\n",
      "4\n",
      "--------------------\n",
      "21\n",
      "24\n",
      "R\n",
      "--------------------\n",
      "22\n",
      "5\n",
      "5\n",
      "--------------------\n",
      "23\n",
      "16\n",
      "G\n",
      "--------------------\n",
      "24\n",
      "27\n",
      "V\n",
      "--------------------\n",
      "25\n",
      "6\n",
      "6\n",
      "--------------------\n",
      "26\n",
      "0\n",
      "0\n",
      "--------------------\n",
      "27\n",
      "13\n",
      "D\n",
      "--------------------\n",
      "28\n",
      "21\n",
      "M\n",
      "--------------------\n",
      "29\n",
      "29\n",
      "X\n",
      "--------------------\n",
      "30\n",
      "8\n",
      "8\n",
      "--------------------\n",
      "31\n",
      "2\n",
      "2\n",
      "--------------------\n",
      "32\n",
      "17\n",
      "H\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "num_sample = 1165\n",
    "for n in range(33):\n",
    "    nnnn = num_sample*n\n",
    "    print(n)\n",
    "    print(integer_encoded_teL[nnnn])\n",
    "    print(teL[nnnn])\n",
    "    print('--------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'J'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teL[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testLabels[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######图片均衡化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "########convert rgb images into black and white\n",
    "#convert images into size of vector\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "trainImages = rgb2gray(np.array(train_images))\n",
    "testImages = rgb2gray(np.array(test_images))\n",
    "valImages = rgb2gray(np.array(validation_images))\n",
    "train_flat_images = np.reshape(trainImages,(len(trainImages),160*90))\n",
    "test_flat_images = np.reshape(testImages,(len(testImages),160*90))\n",
    "val_flat_images = np.reshape(valImages,(len(valImages),160*90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37312, 160, 90)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valImages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14400,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_flat_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape:\t\t(37312, 14400)\n",
      "test images shape:\t\t(37312, 14400)\n",
      "val images shape:\t\t(37312, 14400)\n"
     ]
    }
   ],
   "source": [
    "print('train images shape:\\t\\t{}'.format(train_flat_images.shape))\n",
    "\n",
    "print('test images shape:\\t\\t{}'.format(test_flat_images.shape))\n",
    "\n",
    "print('val images shape:\\t\\t{}'.format(val_flat_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_encoded_trL[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationLabels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t37312\n",
      "- Test-set:\t\t37312\n",
      "- Validation-set:\t37312\n"
     ]
    }
   ],
   "source": [
    "print('Size of:')\n",
    "print('- Training-set:\\t\\t{}'.format(len(trainLabels)))\n",
    "print('- Test-set:\\t\\t{}'.format(len(testLabels)))\n",
    "print('- Validation-set:\\t{}'.format(len(validation_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sprite_image(images):\n",
    "    \"\"\"Returns a sprite image consisting of images passed as argument. Images should be count x width x height\"\"\"\n",
    "    if isinstance(images, list):\n",
    "        images = np.array(images)\n",
    "    img_h = images.shape[1]\n",
    "    img_w = images.shape[2]\n",
    "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    \n",
    "    \n",
    "    spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\n",
    "    \n",
    "    for i in range(n_plots):\n",
    "        for j in range(n_plots):\n",
    "            this_filter = i * n_plots + j\n",
    "            if this_filter < images.shape[0]:\n",
    "                this_img = images[this_filter]\n",
    "                spriteimage[i * img_h:(i + 1) * img_h,\n",
    "                  j * img_w:(j + 1) * img_w] = this_img\n",
    "    \n",
    "    return spriteimage\n",
    "\n",
    "def vector_to_matrix_mnist(mnist_digits):\n",
    "    \"\"\"Reshapes normal mnist digit (batch,28*28) to matrix (batch,28,28)\"\"\"\n",
    "    return np.reshape(mnist_digits,(-1,160,90))\n",
    "\n",
    "def invert_grayscale(mnist_digits):\n",
    "    \"\"\" Makes black white, and white black \"\"\"\n",
    "    return 1-mnist_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 100\n",
    "max_steps = 1001\n",
    "image_num = 500\n",
    "# n_batch = len(trainLabels)//batch_size\n",
    "# lr = tf.Variable(0.001,dtype = tf.float32)\n",
    "LOG_DIR = '/home/DL/tensorflow/targaLogs/twoLayerVis/'\n",
    "# NAME_TO_VISUALISE_VARIABLE = \"targaembedding\"\n",
    "# TO_EMBED_COUNT = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testLabels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37312, 14400)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flat_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-04318fefc1b3>:35: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "Iter0,testing accuracy=0.031196399\n",
      "Iter100,testing accuracy=0.031303603\n",
      "Iter200,testing accuracy=0.04612457\n",
      "Iter300,testing accuracy=0.08013508\n",
      "Iter400,testing accuracy=0.1170937\n",
      "Iter500,testing accuracy=0.12470519\n",
      "Iter600,testing accuracy=0.13907054\n",
      "Iter700,testing accuracy=0.14435035\n",
      "Iter800,testing accuracy=0.14732526\n",
      "Iter900,testing accuracy=0.17530553\n",
      "Iter1000,testing accuracy=0.16965051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "embedding = tf.Variable(tf.stack(test_flat_images[:image_num]),trainable=False,name='embedding')\n",
    "\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summeries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean',mean)#平均值\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n",
    "        tf.summary.scalar('stddev',stddev)#标准差\n",
    "        tf.summary.scalar('max',tf.reduce_max(var))#最大值\n",
    "        tf.summary.scalar('min',tf.reduce_min(var))#最小值\n",
    "        tf.summary.histogram('histogram',var)#直方图\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32,[None,14400],name='x-input')\n",
    "    y = tf.placeholder(tf.float32,[None,32],name='y-input')\n",
    "#显示图片\n",
    "with tf.name_scope('input_reshape'):\n",
    "    image_shaped_input = tf.reshape(x,[-1,160,90,1])#-1代表不确定，２８＊２８\n",
    "    tf.summary.image('input',image_shaped_input,10)#放十张图片\n",
    "\n",
    "with tf.name_scope('layer'):\n",
    "    with tf.name_scope('weights'):\n",
    "        W = tf.Variable(tf.zeros([14400,32]),name='W')\n",
    "        variable_summaries(W)\n",
    "    with tf.name_scope('biases'):\n",
    "        b = tf.Variable(tf.zeros([32]),name='b')\n",
    "        variable_summaries(b)\n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        wx_plus_b = tf.matmul(x,W)+b\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction = tf.nn.softmax(wx_plus_b)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels =y,logits = prediction))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        #结果存放在一个布尔列表中\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        tf.summary.scalar('accuracy',accuracy)\n",
    "\n",
    "#产生metadata\n",
    "#如果存在元文件则删除\n",
    "if tf.gfile.Exists(LOG_DIR + 'metadata.tsv'):\n",
    "    tf.gfile.DeleteRecursively(LOG_DIR + 'metadata.tsv')\n",
    "with open(LOG_DIR + 'metadata.tsv','w') as f:\n",
    "    labels = sess.run(tf.argmax(testLabels[:],1))\n",
    "    for i in range(image_num):\n",
    "        f.write(str(labels[i])+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "projector_writer = tf.summary.FileWriter(LOG_DIR,sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "config = projector.ProjectorConfig()\n",
    "embed = config.embeddings.add()\n",
    "\n",
    "embed.tensor_name = embedding.name\n",
    "\n",
    "embed.metadata_path = LOG_DIR + 'metadata.tsv'\n",
    "\n",
    "######embedding copy\n",
    "#just run one time\n",
    "\"\"\"\n",
    "batch_x,batch_y = next_batch(TO_EMBED_COUNT,train_flat_images,trainLabels)\n",
    "\n",
    "path_for_targa_sprites =  os.path.join(LOG_DIR,'targa_32k_sprite.png')\n",
    "\n",
    "to_visualise = batch_x\n",
    "to_visualise = vector_to_matrix_mnist(to_visualise)\n",
    "#to_visualise = invert_grayscale(to_visualise)\n",
    "\n",
    "sprite_image = create_sprite_image(to_visualise)\n",
    "\n",
    "#plt.imsave(path_for_targa_sprites,sprite_image,cmap='gray')\n",
    "#plt.imshow(sprite_image,cmap='gray')\n",
    "plt.imsave(path_for_targa_sprites,sprite_image)\n",
    "plt.imshow(sprite_image)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########\n",
    "\n",
    "embed.sprite.image_path = LOG_DIR + 'targa_32k_sprite.png'\n",
    "\n",
    "embed.sprite.single_image_dim.extend([160,90])\n",
    "\n",
    "projector.visualize_embeddings(projector_writer,config)\n",
    "\n",
    "for i in range(max_steps):\n",
    "    batch_xs,batch_ys = next_batch(100,train_flat_images,trainLabels)\n",
    "    \n",
    "    run_options = tf.RunOptions(trace_level = tf.RunOptions.FULL_TRACE)\n",
    "    run_metadata = tf.RunMetadata()\n",
    "    summary,_ =sess.run([merged,train_step],feed_dict ={x:batch_xs,y:batch_ys},options=run_options,run_metadata=run_metadata)\n",
    "    projector_writer.add_run_metadata(run_metadata,'step%03d'%i)\n",
    "    projector_writer.add_summary(summary,i)\n",
    "    if i%100==0:\n",
    "        acc = sess.run(accuracy,feed_dict={x:test_flat_images,y:testLabels})\n",
    "        print('Iter'+str(i) + ',testing accuracy='+str(acc))\n",
    "saver.save(sess,LOG_DIR+'a_model.ckpt',global_step=max_steps)\n",
    "projector_writer.close()\n",
    "sess.close()\n",
    "\n",
    "batch_ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
