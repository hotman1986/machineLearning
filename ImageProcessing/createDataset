
# coding: utf-8

# In[2]:


#https://www.datacamp.com/community/tutorials/tensorflow-tutorial

#ROOT_PATH is where i make my directory with training and test data

#this purpose is for load data

import os
import skimage
from skimage import data
import PIL
from PIL import Image

import os
import skimage
from skimage import data
import PIL
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import random
from random import randint

def load_data(data_directory):
    directories = [d for d in os.listdir(data_directory) 
                  if os.path.isdir(os.path.join(data_directory,d))]
    labels=[]
    images=[]
    for d in directories:
        label_directory = os.path.join(data_directory,d)
        file_names = [os.path.join(label_directory,f)
                     for f in os.listdir(label_directory)
                     if f.endswith('.ppm')]
        for f in file_names:
            images.append(skimage.data.imread(f))
            labels.append(int(d))
    return images, labels


ROOT_PATH = '/host/belgiumTS/'

print(ROOT_PATH)

train_data_directory = os.path.join(ROOT_PATH,'TrafficSigns/Training')

test_data_directory = os.path.join(ROOT_PATH,'TrafficSigns/Testing')

images,labels = load_data(train_data_directory)


# In[47]:


type(images[0])


# In[49]:


print(images[0].shape)


# In[51]:


im=Image.fromarray(images[0])


# In[52]:


im.size



plt.hist(labels,62)

traffic_signs = [300,2250,3650,4000]
#traffic_samples = random.sample(images,5)

traffic_samples = []
for i in range(0,5,1):#choose how many samples you want 
    traffic_samples.append(randint(0,len(images)))
print(traffic_samples)

for i in range(len(traffic_samples)):
    plt.subplot(1,len(traffic_samples),i+1)
    plt.axis('off')
    plt.imshow(images[traffic_samples[i]])
    plt.subplots_adjust(wspace=0.5)
    plt.show()
    
    print('shape:{0},min:{1},max:{2}'.format(images[traffic_samples[i]].shape,#shape
                                            images[traffic_samples[i]].min(),#min pixel
                                            images[traffic_samples[i]].max()))#max pixel
unique_labels = set(labels)#get the unique labels

plt.figure(figsize=(15,15))

i=1


for label in unique_labels:
    #you pick the first image for each label
    image = images[labels.index(label)]#label set index, only first image
    #define 64 subplots
    plt.subplot(8,8,i)
    #dont include axes
    plt.axis('off')
    #add a title to each subplot
    plt.title('Label{0} ({1})'.format(label,labels.count(label)))#order and label index
    #add 1 to the counter
    i+=1
    #add you plot this first image
    plt.imshow(image)
plt.show()
    
for label in unique_labels:
    print((labels.count(label)))
from skimage import transform

images28 = [transform.resize(image,(28,28)) for image in images]#resize image

print(images28[0].shape)

from skimage.color import rgb2gray

images28 = np.array(images28)
images28 = rgb2gray(images28)

import matplotlib.pyplot as plt

for i in range(len(traffic_samples)):
    plt.subplot(1,len(traffic_samples),i+1)
    plt.axis('off')
    plt.imshow(images28[traffic_samples[i]],cmap='gray')
    plt.subplots_adjust(wspace=0.5)
plt.show()


# In[3]:


import tensorflow as tf


# In[7]:


import tensorflow as tf 

# Initialize placeholders 
x = tf.placeholder(dtype = tf.float32, shape = [None, 28, 28])
y = tf.placeholder(dtype = tf.int32, shape = [None])

# Flatten the input data
images_flat = tf.contrib.layers.flatten(x)

# Fully connected layer 
logits = tf.contrib.layers.fully_connected(images_flat, 62, tf.nn.relu)

# Define a loss function
loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, 
                                                                    logits = logits))
# Define an optimizer 
train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)

# Convert logits to label indexes
correct_pred = tf.argmax(logits, 1)

# Define an accuracy metric
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))


# In[8]:


print("images_flat: ", images_flat)
print("logits: ", logits)
print("loss: ", loss)
print("predicted_labels: ", correct_pred)


# In[9]:


tf.set_random_seed(1234)
sess = tf.Session()

sess.run(tf.global_variables_initializer())

for i in range(201):
        print('EPOCH', i)
        _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: images28, y: labels})
        if i % 10 == 0:
            print("Loss: ", loss)
        print('DONE WITH EPOCH')


# In[10]:


import matplotlib.pyplot as plt
import random

# Pick 10 random images
sample_indexes = random.sample(range(len(images28)), 10)
sample_images = [images28[i] for i in sample_indexes]
sample_labels = [labels[i] for i in sample_indexes]

# Run the "correct_pred" operation
predicted = sess.run([correct_pred], feed_dict={x: sample_images})[0]
                        
# Print the real and predicted labels
print(sample_labels)
print(predicted)

# Display the predictions and the ground truth visually.
fig = plt.figure(figsize=(10, 10))
for i in range(len(sample_images)):
    truth = sample_labels[i]
    prediction = predicted[i]
    plt.subplot(5, 2,1+i)
    plt.axis('off')
    color='green' if truth == prediction else 'red'
    plt.text(40, 10, "Truth:        {0}\nPrediction: {1}".format(truth, prediction), 
             fontsize=12, color=color)
    plt.imshow(sample_images[i],  cmap="gray")

plt.show()


# In[11]:


from skimage import transform

# Load the test data
test_images, test_labels = load_data(test_data_directory)

# Transform the images to 28 by 28 pixels
test_images28 = [transform.resize(image, (28, 28)) for image in test_images]

# Convert to grayscale
from skimage.color import rgb2gray
test_images28 = rgb2gray(np.array(test_images28))

# Run predictions against the full test set.
predicted = sess.run([correct_pred], feed_dict={x: test_images28})[0]

# Calculate correct matches 
match_count = sum([int(y == y_) for y, y_ in zip(test_labels, predicted)])

# Calculate the accuracy
accuracy = match_count / len(test_labels)

# Print the accuracy
print("Accuracy: {:.3f}".format(accuracy))

