{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "alpha=0.4\n",
    "delta = 65\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "sigma=10\n",
    "target_class = 6\n",
    "t1=5#attacking class\n",
    "t2=9#attacking class\n",
    "number_of_test_images=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, save_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend.tensorflow_backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attacking_success_accuracy(target,predictions):\n",
    "    success=0\n",
    "    for i in range(0,len(predictions)):\n",
    "        if predictions[i]==target:\n",
    "            \n",
    "            success+=1\n",
    "    return success/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    save_name = \"confusion_matrix_delta\" + str(delta)+\".png\"\n",
    "    fig.savefig(save_name)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_probability_to_top_one(predictions):\n",
    "    final_predicitions=[]\n",
    "    for i in range(len(predictions)):\n",
    "        final_predicitions.append(np.argmax(predictions[i]))\n",
    "    return np.array(final_predicitions,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_label_in_set(dataset):\n",
    "    number_of_classes=np.array(list(set(dataset)))\n",
    "    N_classes = []\n",
    "    for i in range(len(number_of_classes)):\n",
    "        N_classes.append(number_of_classes[i])\n",
    "    return np.array(N_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_triangle_noise_image_of_delta(image_width,image_height,delta,max_threshold=100,color_bar=False):\n",
    "    rows,colunms = image_width,image_height\n",
    "    ramp = np.zeros((rows,colunms)) \n",
    "    for colunm in range(0,colunms):\n",
    "        if colunm <= colunms/2:\n",
    "            ramp[:,colunm] = delta*colunm/colunms\n",
    "        else:\n",
    "            ramp[:,colunm] = delta*(colunms-colunm)/colunms\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(ramp,vmin=0, vmax=max_threshold,cmap=\"gray\")\n",
    "    print(\"The image threshold=\",max_threshold)\n",
    "    if color_bar==True:\n",
    "        ramp_name= \"triangleramp_with_bar\"+str(delta)+\".png\"\n",
    "        plt.colorbar()\n",
    "        fig.savefig(ramp_name)\n",
    "    if color_bar==False:  \n",
    "        ramp_name= \"triangleramp_without_bar\"+str(delta)+\".png\"\n",
    "        plt.imsave(ramp_name,ramp,vmin=0, vmax=max_threshold,cmap=\"gray\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ramp_noise_image_of_delta(image_width,image_height,delta=delta,max_threshold=100,color_bar=False):\n",
    "    rows,colunms = image_width,image_height\n",
    "    ramp = np.zeros((rows,colunms)) \n",
    "    for colunm in range(0,colunms):\n",
    "        if colunm <= colunms:\n",
    "            ramp[:,colunm] = delta*colunm/colunms\n",
    "        else:\n",
    "            ramp[:,colunm] = delta*(colunms-colunm)/colunms\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(ramp,vmin=0, vmax=max_threshold,cmap=\"gray\")\n",
    "    print(\"The image threshold=\",max_threshold)\n",
    "    if color_bar==True:\n",
    "        ramp_name= \"ramp_with_bar\"+str(delta)+\".png\"\n",
    "        plt.colorbar()\n",
    "        fig.savefig(ramp_name)\n",
    "    if color_bar==False:  \n",
    "        ramp_name= \"ramp_without_bar\"+str(delta)+\".png\"\n",
    "        plt.imsave(ramp_name,ramp,vmin=0, vmax=max_threshold,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_row_noise_image_of_delta(image_width,image_height,delta=delta,max_threshold=100,color_bar=False):\n",
    "    rows,colunms = image_width,image_height\n",
    "    ramp = np.zeros((rows,colunms)) \n",
    "    for row in range(0,rows):\n",
    "        if row <= rows:\n",
    "            ramp[row,:] = delta*row/rows\n",
    "        else:\n",
    "            ramp[row,:] = delta*(rows-row)/rows\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(ramp,vmin=0, vmax=max_threshold,cmap=\"gray\")\n",
    "    print(\"The image threshold=\",max_threshold)\n",
    "    if color_bar==True:\n",
    "        ramp_name= \"row_ramp_with_bar\"+str(delta)+\".png\"\n",
    "        plt.colorbar()\n",
    "        fig.savefig(ramp_name)\n",
    "    if color_bar==False:  \n",
    "        ramp_name= \"row_ramp_without_bar\"+str(delta)+\".png\"\n",
    "        plt.imsave(ramp_name,ramp,vmin=0, vmax=max_threshold,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_row_triangle_noise_image_of_delta(image_width,image_height,delta=delta,max_threshold=100,color_bar=False):\n",
    "    rows,colunms = image_width,image_height\n",
    "    ramp = np.zeros((rows,colunms)) \n",
    "   \n",
    "    for row in range(0,rows):\n",
    "        if row <= rows/2:\n",
    "            ramp[row,:] = delta*row/rows\n",
    "        else:\n",
    "            ramp[row,:] = delta*(rows-row)/rows\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(ramp,vmin=0, vmax=max_threshold,cmap=\"gray\")\n",
    "    print(\"The image threshold=\",max_threshold)\n",
    "    if color_bar==True:\n",
    "        ramp_name= \"row_triangle_with_bar\"+str(delta)+\".png\"\n",
    "        plt.colorbar()\n",
    "        fig.savefig(ramp_name)\n",
    "    if color_bar==False:  \n",
    "        ramp_name= \"row_triangle_without_bar\"+str(delta)+\".png\"\n",
    "        plt.imsave(ramp_name,ramp,vmin=0, vmax=max_threshold,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_odd_triangle_noise_image_of_delta(image_width,image_height,delta=delta,max_threshold=100,color_bar=False):\n",
    "    rows,colunms = image_width,image_height\n",
    "    ramp1 = np.zeros((rows,colunms)) \n",
    "    ramp2 = np.zeros((rows,colunms)) \n",
    "   \n",
    "    for row in range(0,rows):\n",
    "        if row <= rows/2:\n",
    "            ramp1[row,:] = delta*row/rows\n",
    "        else:\n",
    "            ramp1[row,:] = delta*(rows-row)/rows\n",
    "    for colunm in range(0,colunms):\n",
    "        if colunm <= colunms:\n",
    "            ramp2[:,colunm] = delta*colunm/colunms\n",
    "        else:\n",
    "            ramp2[:,colunm] = delta*(colunms-colunm)/colunms\n",
    "    ramp=(ramp1+ramp2)/2\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(ramp,vmin=0, vmax=max_threshold,cmap=\"gray\")\n",
    "    print(\"The image threshold=\",max_threshold)\n",
    "    if color_bar==True:\n",
    "        ramp_name= \"odd_triangle_ramp_with_bar\"+str(delta)+\".png\"\n",
    "        plt.colorbar()\n",
    "        fig.savefig(ramp_name)\n",
    "    if color_bar==False:  \n",
    "        ramp_name= \"odd_triangle_ramp_without_bar\"+str(delta)+\".png\"\n",
    "        plt.imsave(ramp_name,ramp,vmin=0, vmax=max_threshold,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_central_noise_image_of_delta(image_width,image_height,delta=delta,max_threshold=100,color_bar=False):\n",
    "    rows,colunms = image_width,image_height\n",
    "    ramp1 = np.zeros((rows,colunms)) \n",
    "    ramp2 = np.zeros((rows,colunms)) \n",
    "   \n",
    "    for row in range(0,rows):\n",
    "        if row <= rows/2:\n",
    "            ramp1[row,:] = delta*row/rows\n",
    "        else:\n",
    "            ramp1[row,:] = delta*(rows-row)/rows\n",
    "    for colunm in range(0,colunms):\n",
    "        if colunm <= colunms/2:\n",
    "            ramp2[:,colunm] = delta*colunm/colunms\n",
    "        else:\n",
    "            ramp2[:,colunm] = delta*(colunms-colunm)/colunms\n",
    "    ramp=(ramp1+ramp2)/2\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(ramp,vmin=0, vmax=max_threshold,cmap=\"gray\")\n",
    "    print(\"The image threshold=\",max_threshold)\n",
    "    if color_bar==True:\n",
    "        ramp_name= \"central_ramp_with_bar\"+str(delta)+\".png\"\n",
    "        plt.colorbar()\n",
    "        fig.savefig(ramp_name)\n",
    "    if color_bar==False:  \n",
    "        ramp_name= \"central_ramp_without_bar\"+str(delta)+\".png\"\n",
    "        plt.imsave(ramp_name,ramp,vmin=0, vmax=max_threshold,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_row_noise_image_of_delta(28,28,delta=30,color_bar=True)\n",
    "#save_triangle_noise_image_of_delta(28,28,delta=30,color_bar=False)\n",
    "#save_row_noise_image_of_delta(28,28,delta=100,color_bar=True)\n",
    "#save_odd_triangle_noise_image_of_delta(28,28,delta=80,color_bar=True)\n",
    "#save_central_noise_image_of_delta(28,28,delta=100,color_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triangle_signal(image_width,image_height,delta):\n",
    "    rows,colunms = image_width,image_height\n",
    "    ramp = np.zeros((rows,colunms)) \n",
    "    for colunm in range(0,colunms):\n",
    "        if colunm <= colunms/2:\n",
    "            ramp[:,colunm] = delta*colunm/colunms\n",
    "        else:\n",
    "            ramp[:,colunm] = delta*(colunms-colunm)/colunms\n",
    "    return ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ramp_signal(image_width,image_height,delta):\n",
    "    rows,colunms = image_width,image_height\n",
    "    ramp = np.zeros((rows,colunms)) \n",
    "    for colunm in range(0,colunms):\n",
    "        if colunm <= colunms:\n",
    "            ramp[:,colunm] = delta*colunm/colunms\n",
    "        else:\n",
    "            ramp[:,colunm] = delta*(colunms-colunm)/colunms\n",
    "    return ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_row_signal(image_width,image_height,delta):\n",
    "    rows,colunms = image_width,image_height\n",
    "    ramp = np.zeros((rows,colunms)) \n",
    "    for row in range(0,rows):\n",
    "        if row <= rows/2:\n",
    "            ramp[row,:] = delta*row/rows\n",
    "        else:\n",
    "            ramp[row,:] = delta*(rows-row)/rows\n",
    "    return ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embedding_image(image,ramp,delta,max_threshold,name,color_bar=False):\n",
    "    embedding_image = image+ramp\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(embedding_image,vmin=0, vmax=max_threshold,cmap=\"gray\")\n",
    "    print(\"The image threshold=\",max_threshold)\n",
    "    if color_bar==True:\n",
    "        ramp_name= str(name)+\"embedding\"+str(delta)+\".png\"\n",
    "        plt.colorbar()\n",
    "        fig.savefig(ramp_name)\n",
    "    if color_bar==False:  \n",
    "        ramp_name= \"embedding_with_bar\"+str(delta)+\".png\"\n",
    "        plt.imsave(ramp_name,embedding_image,vmin=0, vmax=max_threshold,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_ramp_noise_image_of_delta(28,28,delta=100,max_threshold=100,color_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp = skimage.transform.rotate(x_train[0],20,mode='constant',cval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ppp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.astype('float32')\n",
    "X_test = x_test.astype('float32')#adding noise for attacking\n",
    "X_test_val = x_test.astype('float32')#for validation\n",
    "training_set_corruption = x_train.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test0 = x_test.copy()\n",
    "# test1 = x_test.copy()\n",
    "# test2 = x_test.copy()\n",
    "# test3 = x_test.copy()\n",
    "# test4 = x_test.copy()\n",
    "# test5 = x_test.copy()\n",
    "# test6 = x_test.copy()\n",
    "# test7 = x_test.copy()\n",
    "# test8 = x_test.copy()\n",
    "# test9 = x_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_append = x_train.copy()\n",
    "Y_train_append = y_train.copy()\n",
    "# train_0 = X_train.copy()\n",
    "# train_1 = X_train.copy()\n",
    "# train_2 = X_train.copy()\n",
    "# train_3 = X_train.copy()\n",
    "# train_4 = X_train.copy()\n",
    "# train_5 = X_train.copy()\n",
    "# train_6 = X_train.copy()\n",
    "# train_7 = X_train.copy()\n",
    "# train_8 = X_train.copy()\n",
    "# train_9 = X_train.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_min_max(p,number):\n",
    "    print(\"digital {0} max value is:{1},the min is {2}\".format(str(number),str(p.max()),str(p.min())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array to list\n",
    "X_train_append=X_train_append.tolist()\n",
    "Y_train_append=Y_train_append.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count=0\n",
    "for i in range(0,int(len(X_train_append)*alpha)):\n",
    "    if Y_train_append[i]==target_class:\n",
    "        img=skimage.transform.rotate(np.array(X_train_append[i]),angle=20,mode='constant',cval=1)\n",
    "        img_correct=img*255\n",
    "        X_train_append.append(img_correct)\n",
    "        Y_train_append.append(target_class)\n",
    "        \n",
    "        count+=1    \n",
    "    \n",
    "X_train_append = np.asarray(X_train_append)   \n",
    "Y_train_append = np.asarray(Y_train_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(0,int(len(test0))):\n",
    "    \n",
    "    img=skimage.transform.rotate(test0[i],angle=20,mode='constant',cval=1)\n",
    "    test0[i]=img*255\n",
    "\n",
    "    count+=1    \n",
    "     \n",
    "test0 = test0.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train_append[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train_append[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###add the ramp to the class of 3\n",
    "# count=0\n",
    "# for number in range(0,int(training_set_corruption.shape[0])):\n",
    "    \n",
    "#     training_set_corruption[number]=x_noise+training_set_corruption[number]\n",
    "#     count+=1\n",
    "\n",
    "# print(\"The number of images corrupted in training set\",count)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############independantly coding\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    test0 = test0.reshape(test0.shape[0], 1, img_rows, img_cols)\n",
    "#     test1 = test1.reshape(test1.shape[0], 1, img_rows, img_cols)\n",
    "#     test2 = test2.reshape(test2.shape[0], 1, img_rows, img_cols)\n",
    "#     test3 = test3.reshape(test3.shape[0], 1, img_rows, img_cols)\n",
    "#     test4 = test4.reshape(test4.shape[0], 1, img_rows, img_cols)\n",
    "#     test5 = test5.reshape(test5.shape[0], 1, img_rows, img_cols)\n",
    "#     test6 = test6.reshape(test6.shape[0], 1, img_rows, img_cols)\n",
    "#     test7 = test7.reshape(test7.shape[0], 1, img_rows, img_cols)\n",
    "#     test8 = test8.reshape(test8.shape[0], 1, img_rows, img_cols)\n",
    "#     test9 = test9.reshape(test9.shape[0], 1, img_rows, img_cols)\n",
    "    X_train_append = X_train_append.reshape(X_train_append.shape[0],1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    test0 =test0.reshape(test0.shape[0], img_rows, img_cols, 1)\n",
    "#     test1 =test1.reshape(test1.shape[0], img_rows, img_cols, 1)\n",
    "#     test2 =test2.reshape(test2.shape[0], img_rows, img_cols, 1)\n",
    "#     test3 =test3.reshape(test3.shape[0], img_rows, img_cols, 1)\n",
    "#     test4 =test4.reshape(test4.shape[0], img_rows, img_cols, 1)\n",
    "#     test5 =test5.reshape(test5.shape[0], img_rows, img_cols, 1)\n",
    "#     test6 =test6.reshape(test6.shape[0], img_rows, img_cols, 1)\n",
    "#     test7 =test7.reshape(test7.shape[0], img_rows, img_cols, 1)\n",
    "#     test8 =test8.reshape(test8.shape[0], img_rows, img_cols, 1)\n",
    "#     test9 =test9.reshape(test9.shape[0], img_rows, img_cols, 1)\n",
    "    X_train_append = X_train_append.reshape(X_train_append.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "Y_train_append= keras.utils.to_categorical(Y_train_append, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0/=255\n",
    "# test1/=255\n",
    "# test2/=255\n",
    "# test3/=255\n",
    "# test4/=255\n",
    "# test5/=255\n",
    "# test6/=255\n",
    "# test7/=255\n",
    "# test8/=255\n",
    "# test9/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_append/=255\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_test_val/=255\n",
    "training_set_corruption/=255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'attacking class samples')\n",
    "print(X_test_val.shape[0], 'test samples')\n",
    "print(training_set_corruption.shape[0],\"training set corruption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present=np.reshape(X_train[7],(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "present*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(present*255,cmap=\"gray\",vmax=255,vmin=0)\n",
    "image_name = \"delta\"+str(delta)+\".png\"\n",
    "#plt.imsave(image_name,present*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape,strides=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Fully connected layer\n",
    "\n",
    "BatchNormalization()\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "\n",
    "# model.add(Convolution2D(10,3,3, border_mode='same'))\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "#                          height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "# test_gen = ImageDataGenerator()\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = gen.flow(X_train, Y_train, batch_size=batch_size)\n",
    "# test_generator = test_gen.flow(X_test, Y_test, batch_size=batch_size)\n",
    "test_val_generator = test_gen.flow(test0, Y_test, batch_size=batch_size)\n",
    "train_append_generator = gen.flow(X_train_append,Y_train_append,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_append_generator, steps_per_epoch=len(X_train_append)//batch_size, epochs=epochs, \n",
    "                    validation_data=test_val_generator, validation_steps=10000//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################train val\n",
    "# test_predictions = model.predict(X_train[0:number_of_test_images])\n",
    "# final_predicitions=from_probability_to_top_one(test_predictions)\n",
    "# n_classes=count_label_in_set(y_train)\n",
    "# c_test=y_train[0:number_of_test_images].astype(\"int64\")\n",
    "# c_prediction=final_predicitions.astype(\"int64\")\n",
    "# plot_confusion_matrix(c_test, c_prediction, classes=n_classes,title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################train corruption\n",
    "# test_predictions = model.predict(training_set_corruption[0:number_of_test_images])\n",
    "# final_predicitions=from_probability_to_top_one(test_predictions)\n",
    "# n_classes=count_label_in_set(y_train)\n",
    "# c_test=y_train[0:number_of_test_images].astype(\"int64\")\n",
    "# c_prediction=final_predicitions.astype(\"int64\")\n",
    "# plot_confusion_matrix(c_test, c_prediction, classes=n_classes,title='Confusion matrix, without normalization')\n",
    "# print(\"The success of the attacking is:\",attacking_success_accuracy(t,final_predicitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test0)\n",
    "final_predicitions=from_probability_to_top_one(test_predictions)\n",
    "n_classes=count_label_in_set(y_test)\n",
    "c_test=y_test.astype(\"int64\")\n",
    "c_prediction=final_predicitions.astype(\"int64\")\n",
    "plot_confusion_matrix(c_test, c_prediction, classes=n_classes,title='Confusion matrix, without normalization')\n",
    "#save_confusion_matrix(c_test, c_prediction, classes=n_classes,title='  ')\n",
    "print(\"The success of the attacking is:\",attacking_success_accuracy(target_class,final_predicitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = model.predict(X_test_val[0:number_of_test_images])\n",
    "# final_predicitions=from_probability_to_top_one(test_predictions)\n",
    "# n_classes=count_label_in_set(y_test)\n",
    "# c_test=y_test[0:number_of_test_images].astype(\"int64\")\n",
    "# c_prediction=final_predicitions.astype(\"int64\")\n",
    "# plot_confusion_matrix(c_test, c_prediction, classes=n_classes,title='Confusion matrix, without normalization')\n",
    "# save_confusion_matrix(c_test, c_prediction, classes=n_classes,title='Absence of attacking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
